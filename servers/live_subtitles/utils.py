from typing import List

from fast_bunkai import FastBunkai


def split_sentences_ja(text: str) -> List[str]:
    """
    Split Japanese text into sentences using FastBunkai.
    
    FastBunkai provides excellent speed and accuracy for punctuated or emoji-rich text.
    For casual/spoken-style text with spaces instead of periods (common in transcripts or chats),
    we apply a lightweight preprocessing step: replace single spaces surrounded by Japanese characters
    with a period (ã€‚) to guide the splitter toward natural clause boundaries.
    
    This keeps the implementation generic, reusable, and minimalâ€”no heavy dependencies beyond fast_bunkai.
    
    Args:
        text: The Japanese text to split.
    
    Returns:
        A list of sentences as strings (stripped of whitespace).
    
    Example:
        >>> text = "3äººã®å…ˆç”Ÿã‹ã‚‰é›»è©±ãŒã‚ã£ãŸ è¿‘åœ°ãªã‚“ã‹å¿ƒå½“ãŸã‚Šã‚ã‚‹?"
        >>> split_sentences_ja(text)
        ['3äººã®å…ˆç”Ÿã‹ã‚‰é›»è©±ãŒã‚ã£ãŸ', 'è¿‘åœ°ãªã‚“ã‹å¿ƒå½“ãŸã‚Šã‚ã‚‹?']
        
        >>> text = "ç¾½ç”°ã‹ã‚‰âœˆï¸å‡ºç™ºã—ã¦ã€å‹ã ã¡ã¨ğŸ£é£Ÿã¹ã¾ã—ãŸã€‚æœ€é«˜ï¼ã¾ãŸè¡ŒããŸã„ãªğŸ˜‚ã§ã‚‚ã€äºˆç®—ã¯å¤§ä¸ˆå¤«ã‹ãªâ€¦?"
        >>> split_sentences_ja(text)
        ['ç¾½ç”°ã‹ã‚‰âœˆï¸å‡ºç™ºã—ã¦ã€å‹ã ã¡ã¨ğŸ£é£Ÿã¹ã¾ã—ãŸã€‚', 'æœ€é«˜ï¼', 'ã¾ãŸè¡ŒããŸã„ãªğŸ˜‚', 'ã§ã‚‚ã€äºˆç®—ã¯å¤§ä¸ˆå¤«ã‹ãªâ€¦?']
    """
    import re
    
    # Preprocess: treat isolated spaces (common in informal text) as potential sentence breaks
    # Only replace spaces that are between Japanese chars (hiragana, katakana, kanji, some punctuation)
    text = re.sub(r'([\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF\u3000-\u303F])[ ]+([\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF\u3000-\u303F])',
                  r'\1ã€‚\2', text)
    
    splitter = FastBunkai()
    sentences = list(splitter(text))
    return [s.strip() for s in sentences if s.strip()]
